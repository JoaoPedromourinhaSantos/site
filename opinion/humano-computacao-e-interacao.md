[Home](https://lesandrop.github.io) | [blog](https://lesandrop.github.io/site/opinion/index.html)

# Perspectivas de análise de como a relação entre o ser humano e a computação tem evoluído ao longo do tempo

**Lesandro Ponciano**

_09 de novembro de 2023_

_Este texto foi elaborado como fala inicial no evento "Diálogos Pertinentes: Filosofia, Ética e Tecnologia" do IFTDJ/ PUC Minas. A gravação do evento está disponível no [canal do youtube do IFTDJ](https://www.youtube.com/watch?v=ROWl9Bj1HXY)._


Neste texto,  eu gostaria de me referir ao _ser humano_ ao criar e se relacionar com a tecnologia. Trato em particular das tecnologias da informação e comunicação. Essas tecnologias incluem processamento, armazenamento e transmissão de informação. Tudo isso vou tratar de forma ampla como _computação_.

A Ciência da Computação é uma área muito jovem. Quase 80 anos. Ao longo desses anos, ela tem entrelaçado o pensar e o construir; a teoria e a engenharia. Há várias correntes de pensamento que se desenvolvem na medida em que a própria tecnologia é criada e aperfeiçoada. Vamos analisar algumas dessas correntes.

## Computação como uma tecnologia

Hoje o substantivo "computador" é empregado para designar uma máquina, um dispositivo eletrônico. Mas nem sempre foi assim. Há mais de 80 anos, antes das máquinas de computar serem criadas, esse termo "computador" era empregado para designar a _profissão_ de algumas pessoas. As pessoas que realizavam computação, criando tabelas logarítmicas, e de navegação. E, por isso, eram chamadas "computadores". Organizações tinham grandes salas, repletas desses computadores. Usavam caneta, papel, tabelas, vários recursos usados para otimizar o trabalho de calcular (velocidade e redução de erros). Alan Turing, em alguns dos seus trabalhos sobre o processo de computação, se inspirou na forma como essas pessoas trabalhavam. 

Por que criar uma máquina de computar? Algumas contas somos capazes de fazer "de cabeça" (de modo mental), outras não. Todos nós já recorremos a papel e caneta para fazer uma conta que exigia mais etapas do que éramos capazes de memorizar. Caneta e papel tornam possível muitos cálculos. Mas com eles o cálculo ainda era lento. Hoje recorremos a computadores (máquinas). Eles são extremamente rápidos. Computadores realizam operações matemáticas bilhões de vezes mais rápido que os seres humanos. Provavelmente, os computadores que eram pessoas _foram os primeiros desempregados_ com o advento dos computadores que são máquinas.

Cálculos são apenas um exemplo de computação. O universo de aplicação dos computadores é diverso. Hoje em dia há computação no relógio, na geladeira, além das formas tradicionais como tablet, smartphone, notebook e computador de mesa.

## Cognição estendida

O ser humano usa tecnologias de informação e comunicação como **Cognição estendida**. Nessa perspectia, a tecnologia é uma extensão do cérebro. Ela é empregada para realizar uma tarefa que excede os limites do nosso sistema cognitivo. Pode ser tanto um limite de armazenamento (não conseguimos lembrar de tudo) ou um limite de processamento (não conseguimos processar gigabytes de informação). Esses limites do ser humano na “tomada de decisão” foram estudados profundamente por Herbert Simon, criador da teoria da racionalidade limitada (_bounded rationality_). 

Essa corrente de pensamento vê a computação como um complemento do nosso corpo. A computação que amplifica e adiciona às habilidades e capacidades que já temos, mas que são limitadas. Essa é uma das correntes que tentam explicar por que esses dispositivos se tornaram tão essenciais. Há um ciclo de dependência aqui. Quanto mais complexo é o ambiente à nossa volta, mais nós precisamos de tecnologias (com memória e processamento) para conseguir compreendê-lo. Mas quanto mais tecnologias usamos, mais complexo é o ambiente à nossa volta se torna.

## Parceiro do discurso

Os seres humanos não eram considerados como _usuários_ das primeiras máquinas de computar. Quando muito, os seres humanos eram considerados _operadores_ da máquina. Eram máquinas rústicas. O ser humano fornecia a computação a ser feita e, depois de algum tempo, coletava o resultado final gerado pela máquina. Somente a partir da década de 70, com a criação dos sistemas interativos, o ser humano passou a ser enfatizado. Surgiu nessa época a perspectiva do computador como um **parceiro do discurso**. O computador como um parceiro com o qual o ser humano estabelece uma interação ou uma conversa (na perspectiva da Engenharia Semiótica). Assim o computador passou a ser visto não como uma máquina, mas como um colega ou interlocutor.

Considere, por exemplo, em sistemas atuais como Cortana, Siri, ou ChatGPT, que tentam entender e falar como se fossem seres humanos. Nesse caso, eles não apenas estendem o sistema cognitivo humano. Eles são parceiros, colegas, interlocutores que estão lá a serviço do ser humano.

## Inteligência Artificial

Para ser um _parceiro do discurso_, o computador deve se equiparar ao ser humano em termos de linguagem e _raciocínio_.  Isso nos traz outra perspectiva teórica e prática que evoluiu em paralelo ao longo das últimas décadas, que é a inteligência artificial. A origem dela, no contexto da computação, está, em grande parte, na análise técnica e filosófica feita por Alan Turing em um artigo publicado em 1950 na revista Mind. O artigo trata da relação entre máquina de computar e inteligência. Ele coloca a pergunta: **pode uma máquina pensar?** Aqui o conceito de _pensar_ ou de _ser inteligente_ é operacional. Pensa ou é inteligente aquilo que eu não consigo diferenciar de algo que eu sei que pensa ou que é inteligente, por exemplo, um ser humano. Desde essa concepção, a evolução da inteligência artificial foi grande. Hoje toda a sociedade (como nós aqui) debate esse assunto em razão das aplicações como ChatGPT, os assistentes pessoais, carros autônomos, Metaverso, Internet das Coisas.

Para que possamos tratar desse assunto com rigor, é importante entender que a área de Inteligência Artificial **não é um monolito**. Há várias formas de aprendizagem por algoritmos que são estudadas nessa área, como aprendizagem por reforço, aprendizagem supervisionada, aprendizagem não-supervisionada, semi-supervisionada. Há abordagens de aprendizagem que são baseadas em dados fornecidos por seres humanos e outras abordagens de aprendizagem que não requer esse tipo de dados.

## Computação estendida

Atualmente fala-se muito no risco do uso de dados pela inteligência artificial, efeitos disso em dimensões como privacidade, nos direitos autorais. Esse é o caso de sistemas como o ChatGPT, que aprende explorando o conhecimento que há na internet.  Neste ponto, há uma construção teórica interessante. Falamos da **cognição estendida**, mas aqui cabe também falar em "computação estendida", pois a capacidade de conhecimento do computador é limitado ao que ensinamos a ele e, portanto, ele se estende com nossa cognição. O ChatGPT nada saberia sem o ser humano.

Sistemas como ChatGPT inovam ao mostrar o que se pode implementar quando se tem aprendizagem em escala extrema. Modelos de aprendizagem gigantescos, com bilhões de hiperparâmetros e que são capazes de representar todo o conhecimento existente na internet. O ChatGPT é um exemplo do que esse tipo de modelo de aprendizagem é capaz.

A inteligência artificial, em seu estágio mais avançado, não é mais baseada em aprendizagem com dados de seres humanos. No estágio mais avançado ela é totalmente autônoma. Ela aprende baseado em suas próprias experiências (como aprendizagem por reforço e alguns conceitos de algoritmos genéticos). Ela não depende do ser humano fornecer dados. Ainda não temos exemplos muito difundidos do uso desse tipo de inteligência artificial. Ela é extremamente difícil de ser desenvolvida. No entanto, uma vez desenvolvida ela impõe vários riscos. O ser humano é capaz de estabelecer pouco controle sobre o processo de aprendizagem dela. Será difícil prever suas ações.

## Sociedade de risco

As perspectivas de cognição estendida, computação estendida, computador como parceiro do discurso e inteligência artificial  têm pelo menos duas dimensões: técnica (engenharia) e teórica. A dimensão teórica é o que discutimos até aqui: a forma como nós percebemos o computador, a forma como o usamos e a importância que damos a ele. A dimensão técnica é o feito da perspectiva na engenharia de sistemas. Engenheiros/projetistas passam a tratar o seu trabalho como implementação dessas perspectivas, buscando alcançá-la. 
Historicamente, a computação evolui na busca pela _inovação_ e nem tanto pela _prudência_. Muitas vezes os riscos não são mitigados. Só se busca uma solução depois do problema ter surgido. Muitas empresas seguem a abordagem de que o projetista tem _licença para errar_ ou que é melhor _pedir desculpas do que pedir permissão_. Por isso, não é incomum a criação de uma tecnologia causar inicialmente grandes conflitos (lembre-se do início dos sistemas Uber, Facebook, WhatsApp). Todos já estiveram envolvidos em conflitos até se adequarem. 

Há uma construção teórica bastante relevante para entender esse cenário. Ela é chamada _risk society_ (de Ulrich Beck), sociedade de risco. É uma sociedade de incertezas muitas vezes derivadas de efeitos colaterais do desenvolvimento científico e tecnológico. Novos conhecimentos e tecnologias causam incertezas.  Esse cenário de percepção de risco permanece até que se construam bases sólidas para análise dessas incertezas, novas diretrizes da sociedade e legislação.

Por tudo isso, o desenvolvimento tecnológico é, e continuará sendo, alvo de várias discussões legais, morais e éticas. As discussões são essenciais para que as tecnologias sejam cada vez mais aderentes ao que as pessoas e a sociedade desejam.

## Leituras recomendadas

BECK, U.; LASH, S.; WYNNE, B. Risk society: towards a new modernity. USA: Sage. v. 17, 1992.

BARBOSA, Simone; SILVA, Bruno. Interação humano-computador. Elsevier Brasil, 2010.

GRIER, D. A. (2013). When computers were human. Princeton University Press.

PONCIANO, L., BRASILEIRO, F., ANDRADE, N., & SAMPAIO, L. (2014). Considering human aspects on strategies for designing and managing distributed human computation. Journal of Internet Services and Applications, 5(1). [https://doi.org/10.1186/s13174-014-0010-4](https://doi.org/10.1186/s13174-014-0010-4 )

PONCIANO, Lesandro. Reflexões sobre o Emprego de Inteligência Artificial em Ciência Participativa e Cidadã. Civis Blog, Brasília, 15 agosto. 2023. Disponível em: [https://www.civis.ibict.br/blog/2023/08/14/ia-ciencia-cidada/](https://www.civis.ibict.br/blog/2023/08/14/ia-ciencia-cidada/) Acesso em: 15 agosto 2023. 

PONCIANO, Lesandro, et al. Designing for pragmatists and fundamentalists: Privacy concerns and attitudes on the internet of things. In: Proceedings of the XVI Brazilian Symposium on Human Factors in Computing Systems. 2017. p. 1-10. 

Ramos, H., Fonseca, M., & Ponciano, L. (2021). Modeling and Evaluating Personas with Software Explainability Requirements. In Communications in Computer and Information Science (Vol. 1478 CCIS, pp. 136–149). Springer Science and Business Media Deutschland GmbH. Disponível em: [https://doi.org/10.1007/978-3-030-92325-9_11](https://doi.org/10.1007/978-3-030-92325-9_11) Acesso em: 29 outubro 2023. 

SANDERS, E. B. N. From user-centered to participatory design approaches. In: Design and the social sciences. EUA: CRC Press, 2002. p. 18-25.

SANTOS, Lesandro Ponciano dos. "Computação por humanos na perspectiva do engajamento e credibilidade de seres humanos e da replicação de tarefas." (2015). Disponível em: [http://dspace.sti.ufcg.edu.br:8080/xmlui/bitstream/handle/riufcg/569/LESANDRO%20PONCIANO%20DOS%20SANTOS%20-%20TESE%20PPGCC%202015..pdf](http://dspace.sti.ufcg.edu.br:8080/xmlui/bitstream/handle/riufcg/569/LESANDRO%20PONCIANO%20DOS%20SANTOS%20-%20TESE%20PPGCC%202015..pdf) Acesso em: 29 outubro 2023. 

TURING, Alan (1950). "Computing Machinery and Intelligence», Mind, LIX (236): 433–460, doi:[10.1093/mind/LIX.236.433](https://doi.org/10.1093/mind/LIX.236.433)

WING, J. M. Computational thinking. Communications of the ACM, v. 49, n. 3, p. 33-35, 2006
